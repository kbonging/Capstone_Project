# main.py
import os, re, pymysql
from typing import List, Dict, Any, Optional
from dotenv import load_dotenv
from fastapi import FastAPI, Request, Query
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse, JSONResponse
from pydantic import BaseModel
from openai import OpenAI
import chromadb

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í™˜ê²½
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
CHROMA_DIR = os.getenv("CHROMA_DIR", "./chroma_index")

client = OpenAI(api_key=OPENAI_API_KEY)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# FastAPI & CORS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
app = FastAPI()
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:3000",
        "http://localhost:5173",
        "http://127.0.0.1:3000",
        "http://127.0.0.1:5173",
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Chroma
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("CHROMA_DIR:", CHROMA_DIR)
chroma = chromadb.PersistentClient(path=CHROMA_DIR)
collection = chroma.get_or_create_collection("revory_docs")
try:
    print("collection count:", collection.count())
except Exception as e:
    print("collection count error:", e)

SYSTEM = (
    "ë‹¹ì‹ ì€ Revory ê³ ê°ì§€ì›/ê°€ì´ë“œ ì±—ë´‡ìž…ë‹ˆë‹¤. "
    "ì˜¤ì§ ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ì— ê·¼ê±°í•´ í•œêµ­ì–´ë¡œ ì •í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ë‹µí•˜ì„¸ìš”. "
    "ì»¨í…ìŠ¤íŠ¸ì— ì—†ìœ¼ë©´ ëª¨ë¥¸ë‹¤ê³  ë‹µí•˜ê³ , í•„ìš”í•œ ê²½ìš° í•œë‘ ê°€ì§€ í›„ì† ì§ˆë¬¸ì„ ì œì•ˆí•˜ì„¸ìš”. "
    "ê°œì¸ì •ë³´(ì „í™”/ì´ë©”ì¼/ì •í™•ì£¼ì†Œ/íšŒì›ì‹ë³„ì •ë³´)ëŠ” ì ˆëŒ€ ë…¸ì¶œí•˜ì§€ ë§ˆì„¸ìš”."
)

class ChatReq(BaseModel):
    message: str
    top_k: int = 6
    user_id: int | None = None
    conversation_id: str | None = None

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìž„ë² ë”©/ì¿¼ë¦¬ í™•ìž¥ (RAG)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
REGIONS = ["ì„œìš¸","ê²½ê¸°","ì¸ì²œ","ë¶€ì‚°","ëŒ€êµ¬","ê´‘ì£¼","ëŒ€ì „","ìš¸ì‚°","ì„¸ì¢…","ê°•ì›","ì¶©ë¶","ì¶©ë‚¨","ì „ë¶","ì „ë‚¨","ê²½ë¶","ê²½ë‚¨","ì œì£¼"]
SYNONYMS = {
    "ì–´ë–»ê²Œ": ["ë°©ë²•","ì ˆì°¨","í•˜ëŠ” ë²•"],
    "ë­ì•¼": ["ì„¤ëª…","ì •ì˜","ê°œìš”"],
    "ì–¸ì œ": ["ê¸°ê°„","ì¼ì •","ë‚ ì§œ"],
    "ëª¨ì§‘ì¤‘": ["ì˜¤í”ˆ","OPEN","ì‹ ì²­ ê°€ëŠ¥"],
    "ë§ˆê°": ["CLOSED","ì‹ ì²­ ì¢…ë£Œ"],
    "ì‹ ì²­ìž": ["ì§€ì›ìž","ì‹ ì²­ ìˆ˜","ì§€ì› ìˆ˜"],
    "ë¦¬ë·° ì œì¶œ": ["í›„ê¸° ì œì¶œ","ë¦¬ë·° ì—…ë¡œë“œ"],
    "ê²½ìŸë¥ ": ["ê²½ìŸ ë¹„ìœ¨","ì§€ì› ëŒ€ë¹„ ëª¨ì§‘"],
}
AUX_BUCKETS = [
    ["ëª¨ì§‘ì¤‘","ë§ˆê°","ì„ ì •","ë°œí‘œ","ê²½ìŸë¥ ","ì‹ ì²­ìž","ë¶ë§ˆí¬","ë¦¬ë·° ì œì¶œ","ë¦¬ë·° ìˆ˜"],
    ["ë°©ë¬¸í˜•","í¬ìž¥í˜•","ë°°ì†¡í˜•","êµ¬ë§¤í˜•"],  # CAM_PROM
    ["ë¸”ë¡œê·¸","ì¸ìŠ¤íƒ€ê·¸ëž¨","ìœ íŠœë¸Œ","í´ë¦½","ë¦´ìŠ¤","ì‡¼ì¸ ","í‹±í†¡"],  # CAM_CHANNEL
    REGIONS,
]

def embed_query(q: str) -> List[float]:
    res = client.embeddings.create(model="text-embedding-3-large", input=[q])
    return res.data[0].embedding

def expand_queries(q: str) -> List[str]:
    base = (q or "").strip()
    if not base:
        return []
    qs = {base}
    for k, vs in SYNONYMS.items():
        if k in base:
            for v in vs:
                qs.add(base.replace(k, v))
    for bucket in AUX_BUCKETS:
        for kw in bucket:
            qs.add(f"{base} {kw}")
    qs.update({f"{base} ê°€ì´ë“œ", f"{base} FAQ", f"{base} ê·œì • ì •ë¦¬"})
    return list(qs)[:16]

def retrieve_context(query: str, k: int) -> dict:
    k = max(2, min(k, 12))
    qvars = expand_queries(query)
    if not qvars:
        return {"chunks": [], "plain": ""}

    all_hits: List[Dict[str, Any]] = []
    for qv in qvars:
        emb = embed_query(qv)
        res = collection.query(
            query_embeddings=[emb],
            n_results=max(k*4, 24),
            include=["documents", "metadatas", "distances"],
        )
        docs = res.get("documents", [[]])[0]
        metas = res.get("metadatas", [[]])[0]
        dists = res.get("distances", [[]])[0]
        for d, m, dist in zip(docs, metas, dists):
            doc = d or ""
            bonus = 0.0
            for token in set(re.split(r"\s+", query)):
                tok = token.strip()
                if tok and tok in doc:
                    bonus -= 0.02
            all_hits.append({
                "doc": doc,
                "meta": m or {},
                "distance": float(dist) + bonus,
                "title": (m or {}).get("title") or "",
                "source": (m or {}).get("source") or "",
                "source_id": (m or {}).get("source_id") or "",
                "uid": f"{(m or {}).get('source','')}:{(m or {}).get('source_id','')}",
            })

    seen = set()
    deduped = []
    for h in sorted(all_hits, key=lambda x: x["distance"]):
        key = f"{h.get('source','')}|{h.get('source_id','')}|{h['doc'][:120]}"
        if key in seen:
            continue
        seen.add(key)
        deduped.append(h)

    final, per_uid = [], {}
    for h in deduped:
        if len(final) >= k:
            break
        cnt = per_uid.get(h["uid"], 0)
        if cnt >= 3:
            continue
        body = re.sub(r"^\[source=.*?\]\s*", "", h["doc"], flags=re.M)
        final.append({**h, "doc": body})
        per_uid[h["uid"]] = cnt + 1

    chunks = []
    for i, h in enumerate(final, start=1):
        header = f"[{i}] {h['title']}" if h["title"] else f"[{i}]"
        if h["source"] or h["source_id"]:
            header += f" (source={h['source']}, id={h['source_id']})"
        chunks.append({
            "rank": i,
            "header": header,
            "body": h["doc"],
            "source": h["source"],
            "source_id": h["source_id"],
            "title": h["title"],
        })

    plain = "\n\n".join([f"{c['header']}\n{c['body']}" for c in chunks])
    return {"chunks": chunks, "plain": plain}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì‘ë‹µ í›„ì²˜ë¦¬
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_SRC_TAG = re.compile(r"\[ì¶œì²˜\s*\d+\]")
_SRC_INLINE = re.compile(r"\[source=.*?\]")
def clean_response_piece(text: str) -> str:
    text = _SRC_TAG.sub("", text)
    text = _SRC_INLINE.sub("", text)
    return text

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# DB ì§ì¡°íšŒ(ê²€ìƒ‰ API & ë‚´ë¶€ í˜¸ì¶œ ê³µìš©)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def sql_conn():
    return pymysql.connect(
        host=os.getenv("MYSQL_HOST"),
        port=int(os.getenv("MYSQL_PORT","3306")),
        user=os.getenv("MYSQL_USER"),
        password=os.getenv("MYSQL_PASSWORD"),
        database=os.getenv("MYSQL_DB"),
        charset="utf8mb4",
        cursorclass=pymysql.cursors.DictCursor,
    )

PROM_MAP = {"ë°©ë¬¸í˜•":"CAMP001","í¬ìž¥í˜•":"CAMP002","ë°°ì†¡í˜•":"CAMP003","êµ¬ë§¤í˜•":"CAMP004"}
CHANNEL_WORDS = ["ë¸”ë¡œê·¸","ì¸ìŠ¤íƒ€ê·¸ëž¨","ìœ íŠœë¸Œ","í´ë¦½","ë¦´ìŠ¤","ì‡¼ì¸ ","í‹±í†¡"]

# â”€â”€ ì¡°ì‚¬/ë¶ˆìš©ì–´ ì²˜ë¦¬ ìœ í‹¸
JOSA = ("ì—ì„œ","ìœ¼ë¡œ","ë¡œ","ì—ê²Œ","ì—","ì˜","ì€","ëŠ”","ì´","ê°€","ì„","ë¥¼",
        "ì™€","ê³¼","ë„","ë§Œ","ê¹Œì§€","ë¶€í„°","ì´ë‚˜","ë‚˜","ëž‘","í•˜ê³ ")

STOPWORDS = {
    "ìº íŽ˜ì¸","ë¦¬ë·°","ë¦¬ë·°ì–´","ì‹ ì²­","ì§€ì›","ê²€ìƒ‰","ëª©ë¡","ì¶”ì²œ",
    "ìžˆì–´","ìžˆë‚˜ìš”","ìžˆë‹ˆ","ìžˆìŒ","ì–´ë””","ì–´ë–¤","í˜¹ì‹œ","ì¸ê°€","ì¸ê±°","ê±°","ê±°ì•¼","êº¼"
}
PREFIX_STOP = ("ëª¨ì§‘", "ëª¨ì§‘ì¤‘", "ë§ˆê°")  # 'ëª¨ì§‘ì¤‘ì¸' ë“± ë³€í˜• í¬í•¨ ì°¨ë‹¨

def strip_josa(word: str) -> str:
    for j in JOSA:
        if word.endswith(j) and len(word) > len(j):
            return word[: -len(j)]
    return word

def parse_filters(text: str):
    """ìžì—°ì–´ì—ì„œ ê°„ë‹¨ížˆ í•„í„° ì¶”ì¶œ (ì¡°ì‚¬ ì œê±° + ë¶ˆìš©ì–´/ì ‘ë‘ì–´ í•„í„°)"""
    text = (text or "").strip()

    # 1) 1ì°¨ í•„í„° íƒì§€
    region  = next((r for r in REGIONS if r in text), None)
    prom    = next((p for p in PROM_MAP.keys() if p in text), None)
    channel = next((c for c in CHANNEL_WORDS if c in text), None)
    tl = text.lower()
    status = "ëª¨ì§‘ì¤‘" if ("ëª¨ì§‘ì¤‘" in text or "ì‹ ì²­ ê°€ëŠ¥" in text or "open" in tl) else (
             "ë§ˆê°"   if ("ë§ˆê°" in text or "closed" in tl) else None)

    # 2) í‚¤ì›Œë“œ ì¶”ì¶œ
    exclude = {region, prom, channel, "ëª¨ì§‘ì¤‘", "ë§ˆê°", None}
    if region:
        for j in JOSA:
            exclude.add(region + j)

    kw = None
    for tok in re.findall(r"[ê°€-íž£A-Za-z0-9]{2,}", text):
        base = strip_josa(tok)

        # (a) ì´ë¯¸ ì‚¬ìš©í•œ í•„í„°/ì§€ì—­/ì±„ë„/ìœ í˜• ë°°ì œ
        if base in exclude:
            continue
        if base in REGIONS or base in PROM_MAP or base in CHANNEL_WORDS:
            continue

        # (b) ë¶ˆìš©ì–´ ë°°ì œ
        if base in STOPWORDS:
            continue

        # (c) 'ìº íŽ˜ì¸*' ë¥˜, 'ëª¨ì§‘/ëª¨ì§‘ì¤‘/ë§ˆê°' ì ‘ë‘ì–´ ë°°ì œ
        if "ìº íŽ˜ì¸" in base:
            continue
        if base.startswith(PREFIX_STOP):
            continue
        if base.endswith("ì¸") and base[:-1] in PREFIX_STOP:  # ëª¨ì§‘ì¤‘+ì¸
            continue

        # (d) ì§€ì—­ ë³€í˜• ë°©ì–´ (ì„œìš¸ì—/ì„œìš¸ìª½ ë“±)
        if region and (base == region or region in base):
            continue

        kw = base
        break

    return {"region": region, "prom": prom, "channel": channel, "status": status, "q": kw}

def db_search(params, limit=10):
    sql = """
      SELECT c.CAMPAIGN_IDX, c.TITLE,
             COALESCE(r.region,'ì˜¨ë¼ì¸/ì „êµ­') AS region,
             c.CAMPAIGN_TYPE, c.CAM_CATE_CODE, c.CHANNEL_CODE,
             c.RECRUIT_STATUS,
             DATE_FORMAT(c.APPLY_START_DATE,'%%Y-%%m-%%d') AS APPLY_START_DATE,
             DATE_FORMAT(c.APPLY_END_DATE,'%%Y-%%m-%%d')   AS APPLY_END_DATE,
             DATE_FORMAT(c.EXP_START_DATE,'%%Y-%%m-%%d')   AS EXP_START_DATE,
             DATE_FORMAT(c.EXP_END_DATE,'%%Y-%%m-%%d')     AS EXP_END_DATE,
             DATE_FORMAT(c.DEADLINE_DATE,'%%Y-%%m-%%d')    AS DEADLINE_DATE,
             COALESCE(s.total_app,0) AS total_app,
             COALESCE(s.approved_cnt,0) AS approved_cnt,
             COALESCE(rv.review_cnt,0) AS review_cnt,
             COALESCE(bm.bookmark_cnt,0) AS bookmark_cnt
      FROM tb_campaign c
      LEFT JOIN (
        SELECT CAMPAIGN_IDX,
          CASE
            WHEN ADDRESS LIKE '%%ì„œìš¸%%' THEN 'ì„œìš¸'
            WHEN ADDRESS LIKE '%%ê²½ê¸°%%' THEN 'ê²½ê¸°'
            WHEN ADDRESS LIKE '%%ì¸ì²œ%%' THEN 'ì¸ì²œ'
            WHEN ADDRESS LIKE '%%ë¶€ì‚°%%' THEN 'ë¶€ì‚°'
            WHEN ADDRESS LIKE '%%ëŒ€êµ¬%%' THEN 'ëŒ€êµ¬'
            WHEN ADDRESS LIKE '%%ê´‘ì£¼%%' THEN 'ê´‘ì£¼'
            WHEN ADDRESS LIKE '%%ëŒ€ì „%%' THEN 'ëŒ€ì „'
            WHEN ADDRESS LIKE '%%ìš¸ì‚°%%' THEN 'ìš¸ì‚°'
            WHEN ADDRESS LIKE '%%ì„¸ì¢…%%' THEN 'ì„¸ì¢…'
            WHEN ADDRESS LIKE '%%ê°•ì›%%' THEN 'ê°•ì›'
            WHEN ADDRESS LIKE '%%ì¶©ë¶%%' THEN 'ì¶©ë¶'
            WHEN ADDRESS LIKE '%%ì¶©ë‚¨%%' THEN 'ì¶©ë‚¨'
            WHEN ADDRESS LIKE '%%ì „ë¶%%' THEN 'ì „ë¶'
            WHEN ADDRESS LIKE '%%ì „ë‚¨%%' THEN 'ì „ë‚¨'
            WHEN ADDRESS LIKE '%%ê²½ë¶%%' THEN 'ê²½ë¶'
            WHEN ADDRESS LIKE '%%ê²½ë‚¨%%' THEN 'ê²½ë‚¨'
            WHEN ADDRESS LIKE '%%ì œì£¼%%' THEN 'ì œì£¼'
            ELSE 'ì˜¨ë¼ì¸/ì „êµ­'
          END AS region
        FROM tb_campaign_visit
        GROUP BY CAMPAIGN_IDX, region
      ) r ON r.CAMPAIGN_IDX=c.CAMPAIGN_IDX
      LEFT JOIN (
        SELECT
          t.CAMPAIGN_IDX,
          SUM(cnt) AS total_app,
          SUM(CASE WHEN t.APPLY_STATUS_CODE='CAMAPP_APPROVED' AND t.DEL_YN='N' THEN t.cnt ELSE 0 END) AS approved_cnt
        FROM (
          SELECT CAMPAIGN_IDX, APPLY_STATUS_CODE, DEL_YN, COUNT(*) AS cnt
          FROM tb_campaign_application
          GROUP BY CAMPAIGN_IDX, APPLY_STATUS_CODE, DEL_YN
        ) t
        GROUP BY t.CAMPAIGN_IDX
      ) s ON s.CAMPAIGN_IDX=c.CAMPAIGN_IDX
      LEFT JOIN (
        SELECT ca.CAMPAIGN_IDX, COUNT(r.REVIEW_IDX) AS review_cnt
        FROM tb_review r
        JOIN tb_campaign_application ca ON ca.APPLICATION_IDX=r.APPLICATION_IDX
        GROUP BY ca.CAMPAIGN_IDX
      ) rv ON rv.CAMPAIGN_IDX=c.CAMPAIGN_IDX
      LEFT JOIN (
        SELECT CAMPAIGN_IDX, COUNT(*) AS bookmark_cnt
        FROM tb_bookmark
        GROUP BY CAMPAIGN_IDX
      ) bm ON bm.CAMPAIGN_IDX=c.CAMPAIGN_IDX
      WHERE IFNULL(c.DEL_YN,'N')='N'
    """
    args = []
    if params.get("q"):
        sql += " AND (c.TITLE LIKE %s OR c.MISSION LIKE %s OR c.KEYWORD_1 LIKE %s OR c.KEYWORD_2 LIKE %s OR c.KEYWORD_3 LIKE %s)"
        args += [f"%{params['q']}%"]*5
    if params.get("region"):
        sql += " AND COALESCE(r.region,'ì˜¨ë¼ì¸/ì „êµ­') = %s"
        args.append(params["region"])
    if params.get("prom"):
        code = PROM_MAP.get(params["prom"], params["prom"])
        sql += " AND c.CAMPAIGN_TYPE = %s"
        args.append(code)
    if params.get("channel"):
        sql += " AND (c.CHANNEL_CODE = %s OR EXISTS (SELECT 1 FROM tb_common_code cc WHERE cc.code_id=c.CHANNEL_CODE AND cc.code_nm=%s))"
        args += [params["channel"], params["channel"]]
    if params.get("status"):
        if params["status"] == "ëª¨ì§‘ì¤‘":
            sql += " AND c.RECRUIT_STATUS='OPEN'"
        elif params["status"] == "ë§ˆê°":
            sql += " AND c.RECRUIT_STATUS='CLOSED'"

    sql += " ORDER BY (c.RECRUIT_STATUS='OPEN') DESC, bm.bookmark_cnt DESC, s.total_app DESC, c.REG_DATE DESC LIMIT %s"
    args.append(limit)

    with sql_conn() as conn, conn.cursor() as cur:
        cur.execute(sql, args)
        return cur.fetchall()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ê²€ìƒ‰ API (í”„ë¡ íŠ¸ì—ì„œ ì§ì ‘ í˜¸ì¶œìš©) â€” ì„ íƒì‚¬í•­
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.get("/api/campaigns/search")
def campaigns_search(
    q: Optional[str] = Query(None, description="í‚¤ì›Œë“œ(ì œëª©/í‚¤ì›Œë“œ/ë¯¸ì…˜)"),
    region: Optional[str] = Query(None, description="ì„œìš¸/ë¶€ì‚°/..."),
    prom: Optional[str] = Query(None, description="ë°©ë¬¸í˜•/í¬ìž¥í˜•/ë°°ì†¡í˜•/êµ¬ë§¤í˜• ë˜ëŠ” ì½”ë“œ"),
    channel: Optional[str] = Query(None, description="ë¸”ë¡œê·¸/ì¸ìŠ¤íƒ€ê·¸ëž¨/ìœ íŠœë¸Œ/â€¦ ë˜ëŠ” ì½”ë“œ"),
    status: Optional[str] = Query(None, description="ëª¨ì§‘ì¤‘/ë§ˆê°"),
    limit: int = 20,
    offset: int = 0,
):
    params = {"q": q, "region": region, "prom": prom, "channel": channel, "status": status}
    rows = db_search(params, limit=limit)
    return rows

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í—¬ìŠ¤/ë””ë²„ê·¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.get("/health")
def health():
    return {"ok": True}

@app.get("/debug/search")
def debug_search(q: str, k: int = 6):
    ctx = retrieve_context(q, k)
    return JSONResponse({"chunks": ctx["chunks"]})

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìŠ¤íŠ¸ë¦¬ë° ì±—
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.post("/chat/stream")
def chat_stream(req: ChatReq, request: Request):
    # 1) í•„í„°ì„± ì˜ë„ íŒë³„
    filt = parse_filters(req.message)
    is_filter_like = any([filt["region"], filt["prom"], filt["channel"], filt["status"]]) \
        or ("ì°¾ì•„" in req.message or "ë­ ìžˆì–´" in req.message or "ëª©ë¡" in req.message or "ì¶”ì²œ" in req.message)

    if is_filter_like:
        rows = db_search(filt, limit=10)

        def gen_list():
            hdr = []
            if filt.get("region"): hdr.append(f"ì§€ì—­={filt['region']}")
            if filt.get("prom"): hdr.append(f"ìœ í˜•={filt['prom']}")
            if filt.get("channel"): hdr.append(f"ì±„ë„={filt['channel']}")
            if filt.get("status"): hdr.append(f"ìƒíƒœ={filt['status']}")
            if filt.get("q"): hdr.append(f"í‚¤ì›Œë“œ={filt['q']}")
            hdr_text = ", ".join(hdr) if hdr else "ëª¨ë“  ìº íŽ˜ì¸"

            if not rows:
                yield f"data: ðŸ”Ž ê²€ìƒ‰ê²°ê³¼ ({hdr_text})ê°€ ì—†ìŠµë‹ˆë‹¤. ì§€ì—­/ìœ í˜•/ì±„ë„/ìƒíƒœë¥¼ ë°”ê¿”ë³´ì„¸ìš”.\n\n"
                yield "data: [DONE]\n\n"
                return

            yield f"data: ðŸ”Ž ê²€ìƒ‰ê²°ê³¼ ({hdr_text}) ìƒìœ„ {len(rows)}ê±´:\n\n"
            for i, r in enumerate(rows, 1):
                line = (
                    f"{i}. {r['TITLE']} Â· {r['region']} Â· ìƒíƒœ:{'ëª¨ì§‘ì¤‘' if r['RECRUIT_STATUS']=='OPEN' else 'ë§ˆê°'} "
                    f"(ì‹ ì²­:{r['total_app']}, ë‹¹ì²¨:{r['approved_cnt']}, ë¦¬ë·°:{r['review_cnt']}, ë¶ë§ˆí¬:{r['bookmark_cnt']}) "
                    f"ëª¨ì§‘:{r['APPLY_START_DATE']}~{r['APPLY_END_DATE']} | ì²´í—˜:{r['EXP_START_DATE']}~{r['EXP_END_DATE']}"
                )
                yield f"data: {line}\n\n"

            yield "data: \n\n"
            yield "data: â€¢ íŠ¹ì • ìº íŽ˜ì¸ ìƒì„¸ê°€ ê¶ê¸ˆí•˜ë©´ ì œëª© í‚¤ì›Œë“œë¡œ ë¬¼ì–´ë³´ì„¸ìš” (ì˜ˆ: \"OOO ìº íŽ˜ì¸ ê²½ìŸë¥ ? ë¦¬ë·° ë§ˆê°?\")\n\n"
            yield "data: [DONE]\n\n"

        return StreamingResponse(
            gen_list(),
            media_type="text/event-stream",
            headers={"Cache-Control":"no-cache","X-Accel-Buffering":"no"},
        )

    # 2) ì„¤ëª…/ê°€ì´ë“œ/ì •ì±… ë“±ì€ RAG
    ctx_obj = retrieve_context(req.message, req.top_k)
    ctx_plain = (ctx_obj.get("plain") or "").strip()

    if not ctx_plain:
        retry_msg = f"{req.message} ê°€ì´ë“œ FAQ ì •ì±… ë„ì›€ë§ ëª¨ì§‘ì¤‘ ì§€ì—­ ì±„ë„ ìœ í˜• ê²½ìŸë¥  ì‹ ì²­ìž ë¦¬ë·° ì œì¶œ ë¶ë§ˆí¬"
        ctx_obj = retrieve_context(retry_msg, max(req.top_k, 10))
        ctx_plain = (ctx_obj.get("plain") or "").strip()

    if not ctx_plain:
        def noctx_gen():
            yield "data: ì•„ì§ ë‚´ë¶€ ë¬¸ì„œì—ì„œ ë‹µì„ ëª» ì°¾ì•˜ì–´ìš”. ì˜ˆ: 'ì„œìš¸ ë°©ë¬¸í˜• ëª¨ì§‘ì¤‘', 'ì´ ìº íŽ˜ì¸ ê²½ìŸë¥ ', 'ë°°ì†¡í˜• ì‹ ì²­ ë°©ë²•'ì²˜ëŸ¼ êµ¬ì²´ì ìœ¼ë¡œ ë¬¼ì–´ë´ ì£¼ì„¸ìš”.\n\n"
            yield "data: [DONE]\n\n"
        return StreamingResponse(noctx_gen(), media_type="text/event-stream",
                                 headers={"Cache-Control": "no-cache","X-Accel-Buffering":"no"})

    messages = [
        {"role": "system", "content": SYSTEM},
        {"role": "system", "content": f"ì»¨í…ìŠ¤íŠ¸(ë²ˆí˜¸ì™€ ì¶œì²˜ í¬í•¨):\n{ctx_plain}"},
        {"role": "user", "content": req.message},
    ]

    def gen_rag():
        try:
            stream = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=messages,
                temperature=0.2,
                stream=True,
            )
            for chunk in stream:
                delta = chunk.choices[0].delta.content or ""
                if delta:
                    delta = clean_response_piece(delta)
                    if delta:
                        yield f"data: {delta}\n\n"
        except Exception as e:
            yield f"data: [ERROR] {str(e)}\n\n"
        yield "data: [DONE]\n\n"

    return StreamingResponse(
        gen_rag(),
        media_type="text/event-stream",
        headers={"Cache-Control": "no-cache","X-Accel-Buffering":"no"},
    )

# (ì˜µì…˜) ì—°ê²° ì¢…ë£Œ ê°ì§€ ìŠ¤í…
def await_disconnected(request: Request) -> bool:
    return False
