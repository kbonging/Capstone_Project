# main.py
import os, re, pymysql
from typing import List, Dict, Any, Optional
from dotenv import load_dotenv
from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from openai import OpenAI
import chromadb
from difflib import get_close_matches

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í™˜ê²½
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
CHROMA_DIR = os.getenv("CHROMA_DIR", "./chroma_index")
client = OpenAI(api_key=OPENAI_API_KEY)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# FastAPI & CORS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
app = FastAPI()
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:3000",
        "http://localhost:5173",
        "http://127.0.0.1:3000",
        "http://127.0.0.1:5173",
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Chroma (RAG)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("CHROMA_DIR:", CHROMA_DIR)
chroma = chromadb.PersistentClient(path=CHROMA_DIR)
collection = chroma.get_or_create_collection("revory_docs")
try:
    print("collection count:", collection.count())
except Exception as e:
    print("collection count error:", e)

SYSTEM = (
    "ë‹¹ì‹ ì€ Revory ê³ ê°ì§€ì›/ê°€ì´ë“œ ì±—ë´‡ìž…ë‹ˆë‹¤. "
    "ì˜¤ì§ ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ì— ê·¼ê±°í•´ í•œêµ­ì–´ë¡œ ì •í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ë‹µí•˜ì„¸ìš”. "
    "ì»¨í…ìŠ¤íŠ¸ì— ì—†ìœ¼ë©´ ëª¨ë¥¸ë‹¤ê³  ë‹µí•˜ê³ , í•„ìš”í•œ ê²½ìš° í•œë‘ ê°€ì§€ í›„ì† ì§ˆë¬¸ì„ ì œì•ˆí•˜ì„¸ìš”. "
    "ê°œì¸ì •ë³´(ì „í™”/ì´ë©”ì¼/ì •í™•ì£¼ì†Œ/íšŒì›ì‹ë³„ì •ë³´)ëŠ” ì ˆëŒ€ ë…¸ì¶œí•˜ì§€ ë§ˆì„¸ìš”."
)

class ChatReq(BaseModel):
    message: str
    top_k: int = 6
    user_id: int | None = None
    conversation_id: str | None = None

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìž„ë² ë”©/ì¿¼ë¦¬ í™•ìž¥ (RAG)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
REGIONS = ["ì„œìš¸","ê²½ê¸°","ì¸ì²œ","ë¶€ì‚°","ëŒ€êµ¬","ê´‘ì£¼","ëŒ€ì „","ìš¸ì‚°","ì„¸ì¢…","ê°•ì›","ì¶©ë¶","ì¶©ë‚¨","ì „ë¶","ì „ë‚¨","ê²½ë¶","ê²½ë‚¨","ì œì£¼"]
SYNONYMS = {
    "ì–´ë–»ê²Œ": ["ë°©ë²•","ì ˆì°¨","í•˜ëŠ” ë²•"],
    "ë­ì•¼": ["ì„¤ëª…","ì •ì˜","ê°œìš”"],
    "ì–¸ì œ": ["ê¸°ê°„","ì¼ì •","ë‚ ì§œ"],
    "ëª¨ì§‘ì¤‘": ["ì˜¤í”ˆ","OPEN","ì‹ ì²­ ê°€ëŠ¥"],
    "ë§ˆê°": ["CLOSED","ì‹ ì²­ ì¢…ë£Œ"],
    "ì‹ ì²­ìž": ["ì§€ì›ìž","ì‹ ì²­ ìˆ˜","ì§€ì› ìˆ˜"],
    "ë¦¬ë·° ì œì¶œ": ["í›„ê¸° ì œì¶œ","ë¦¬ë·° ì—…ë¡œë“œ"],
    "ê²½ìŸë¥ ": ["ê²½ìŸ ë¹„ìœ¨","ì§€ì› ëŒ€ë¹„ ëª¨ì§‘"],
}
AUX_BUCKETS = [
    ["ëª¨ì§‘ì¤‘","ë§ˆê°","ì„ ì •","ë°œí‘œ","ê²½ìŸë¥ ","ì‹ ì²­ìž","ë¶ë§ˆí¬","ë¦¬ë·° ì œì¶œ","ë¦¬ë·° ìˆ˜"],
    ["ë°©ë¬¸í˜•","í¬ìž¥í˜•","ë°°ì†¡í˜•","êµ¬ë§¤í˜•"],
    ["ë¸”ë¡œê·¸","ì¸ìŠ¤íƒ€ê·¸ëž¨","ìœ íŠœë¸Œ","í´ë¦½","ë¦´ìŠ¤","ì‡¼ì¸ ","í‹±í†¡"],
    REGIONS,
]

def embed_query(q: str) -> List[float]:
    res = client.embeddings.create(model="text-embedding-3-large", input=[q])
    return res.data[0].embedding

def expand_queries(q: str) -> List[str]:
    base = (q or "").strip()
    if not base: return []
    qs = {base}
    for k, vs in SYNONYMS.items():
        if k in base:
            for v in vs:
                qs.add(base.replace(k, v))
    for bucket in AUX_BUCKETS:
        for kw in bucket:
            qs.add(f"{base} {kw}")
    qs.update({f"{base} ê°€ì´ë“œ", f"{base} FAQ", f"{base} ê·œì • ì •ë¦¬"})
    return list(qs)[:16]

def retrieve_context(query: str, k: int) -> dict:
    k = max(2, min(k, 12))
    qvars = expand_queries(query)
    if not qvars: return {"chunks": [], "plain": ""}

    all_hits: List[Dict[str, Any]] = []
    for qv in qvars:
        emb = embed_query(qv)
        res = collection.query(
            query_embeddings=[emb],
            n_results=max(k*4, 24),
            include=["documents","metadatas","distances"],
        )
        docs = res.get("documents", [[]])[0]
        metas = res.get("metadatas", [[]])[0]
        dists = res.get("distances", [[]])[0]
        for d, m, dist in zip(docs, metas, dists):
            doc = d or ""
            bonus = 0.0
            for token in set(re.split(r"\s+", query)):
                tok = token.strip()
                if tok and tok in doc:
                    bonus -= 0.02
            all_hits.append({
                "doc": doc,
                "meta": m or {},
                "distance": float(dist) + bonus,
                "title": (m or {}).get("title") or "",
                "source": (m or {}).get("source") or "",
                "source_id": (m or {}).get("source_id") or "",
                "uid": f"{(m or {}).get('source','')}:{(m or {}).get('source_id','')}",
            })

    seen, deduped = set(), []
    for h in sorted(all_hits, key=lambda x: x["distance"]):
        key = f"{h.get('source','')}|{h.get('source_id','')}|{h['doc'][:120]}"
        if key in seen: continue
        seen.add(key); deduped.append(h)

    final, per_uid = [], {}
    for h in deduped:
        if len(final) >= k: break
        cnt = per_uid.get(h["uid"], 0)
        if cnt >= 3: continue
        body = re.sub(r"^\[source=.*?\]\s*", "", h["doc"], flags=re.M)
        final.append({**h, "doc": body})
        per_uid[h["uid"]] = cnt + 1

    chunks = []
    for i, h in enumerate(final, start=1):
        header = f"[{i}] {h['title']}" if h["title"] else f"[{i}]"
        if h["source"] or h["source_id"]:
            header += f" (source={h['source']}, id={h['source_id']})"
        chunks.append({"rank": i, "header": header, "body": h["doc"], "source": h["source"], "source_id": h["source_id"], "title": h["title"]})
    plain = "\n\n".join(f"{c['header']}\n{c['body']}" for c in chunks)
    return {"chunks": chunks, "plain": plain}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì‘ë‹µ í›„ì²˜ë¦¬ (ì¶œì²˜ íƒœê·¸ ì œê±°)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_SRC_TAG = re.compile(r"\[ì¶œì²˜\s*\d+\]")
_SRC_INLINE = re.compile(r"\[source=.*?\]")
def clean_response_piece(text: str) -> str:
    text = _SRC_TAG.sub("", text)
    text = _SRC_INLINE.sub("", text)
    return text

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# DB ì—°ê²°/ìœ í‹¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def sql_conn():
    return pymysql.connect(
        host=os.getenv("MYSQL_HOST"),
        port=int(os.getenv("MYSQL_PORT","3306")),
        user=os.getenv("MYSQL_USER"),
        password=os.getenv("MYSQL_PASSWORD"),
        database=os.getenv("MYSQL_DB"),
        charset="utf8mb4",
        cursorclass=pymysql.cursors.DictCursor,
    )

PROM_MAP = {"ë°©ë¬¸í˜•":"CAMP001","í¬ìž¥í˜•":"CAMP002","ë°°ì†¡í˜•":"CAMP003","êµ¬ë§¤í˜•":"CAMP004"}
CHANNEL_WORDS = ["ë¸”ë¡œê·¸","ì¸ìŠ¤íƒ€ê·¸ëž¨","ìœ íŠœë¸Œ","í´ë¦½","ë¦´ìŠ¤","ì‡¼ì¸ ","í‹±í†¡"]

# ì±„ë„ ì½”ë“œ/ë³„ì¹­ ë§µ (ê³µí†µì½”ë“œ: CAMC001~CAMC008)
CHANNEL_MAP = {
    "ë¸”ë¡œê·¸":       ["ë¸”ë¡œê·¸", "blog", "naver blog", "CAMC001"],
    "ì¸ìŠ¤íƒ€ê·¸ëž¨":   ["ì¸ìŠ¤íƒ€ê·¸ëž¨", "ì¸ìŠ¤íƒ€", "instagram", "ig", "CAMC002"],
    "ë¸”ë¡œê·¸+í´ë¦½":  ["ë¸”ë¡œê·¸+í´ë¦½", "ë¸”ë¡œê·¸ + í´ë¦½", "ë¸”í´", "CAMC003"],
    "í´ë¦½":         ["í´ë¦½", "clip", "CAMC004"],
    "ë¦´ìŠ¤":         ["ë¦´ìŠ¤", "reels", "CAMC005"],
    "ìœ íŠœë¸Œ":       ["ìœ íŠœë¸Œ", "youtube", "yt", "CAMC006"],
    "ì‡¼ì¸ ":         ["ì‡¼ì¸ ", "shorts", "CAMC007"],
    "í‹±í†¡":         ["í‹±í†¡", "tiktok", "CAMC008"],
}
CHANNEL_CODES_BY_NAME = {
    "ë¸”ë¡œê·¸": ["CAMC001","CAMC003"],
    "ì¸ìŠ¤íƒ€ê·¸ëž¨": ["CAMC002"],
    "ë¸”ë¡œê·¸+í´ë¦½": ["CAMC003"],
    "í´ë¦½": ["CAMC004","CAMC003"],
    "ë¦´ìŠ¤": ["CAMC005"],
    "ìœ íŠœë¸Œ": ["CAMC006","CAMC007"],
    "ì‡¼ì¸ ": ["CAMC007"],
    "í‹±í†¡": ["CAMC008"],
}

# ì¡°ì‚¬/ë¶ˆìš©ì–´
JOSA = ("ì—ì„œ","ìœ¼ë¡œ","ë¡œ","ì—ê²Œ","ì—","ì˜","ì€","ëŠ”","ì´","ê°€","ì„","ë¥¼","ì™€","ê³¼","ë„","ë§Œ","ê¹Œì§€","ë¶€í„°","ì´ë‚˜","ë‚˜","ëž‘","í•˜ê³ ")
STOPWORDS = {
    "ìº íŽ˜ì¸","ë¦¬ë·°","ë¦¬ë·°ì–´","ì‹ ì²­","ì§€ì›","ê²€ìƒ‰","ëª©ë¡","ì¶”ì²œ",
    "ìžˆì–´","ìžˆë‚˜ìš”","ìžˆë‹ˆ","ìžˆìŒ","ì–´ë””","ì–´ë–¤","í˜¹ì‹œ","ì¸ê°€","ì¸ê±°","ê±°","ê±°ì•¼","êº¼",
    "ë°©ë²•","ì œì¶œ","ì•Œë ¤ì¤˜","ì—…ë¡œë“œ","ì ˆì°¨",
    "ì¶”ì²œí•´ì¤˜","ì¶”ì²œì¢€","ì¶”ì²œí•´","ì¶”ì²œí•´ë³¼ê¹Œ","ì¶”ì²œí•´ì£¼ë¼","ì¶”ì²œì£¼ë¼",
    "ì°¾ì•„ì¤˜","ë³´ì—¬ì¤˜","ê³¨ë¼ì¤˜","ë§í•´ì¤˜","ê°€ë¥´ì³ì¤˜","ë¶€íƒ","ìš”ì²­",
}
PREFIX_STOP = ("ëª¨ì§‘","ëª¨ì§‘ì¤‘","ë§ˆê°")
def strip_josa(word: str) -> str:
    for j in JOSA:
        if word.endswith(j) and len(word) > len(j):
            return word[:-len(j)]
    return word

# ìžì—°ì–´ ì •ê·œí™”/ì˜ë„
NORMALIZE_MAP = {
    "ì¼íŽ˜ì¸":"ìº íŽ˜ì¸","ëª¨ì§‘ ì¤‘":"ëª¨ì§‘ì¤‘","ì˜¤í”ˆ":"OPEN",
    "ì—´ì—ˆì–´":"ëª¨ì§‘ì¤‘","ë°›ë‚˜ìš”":"ëª¨ì§‘ì¤‘","ë°›ì•„?":"ëª¨ì§‘ì¤‘",
    "ìžˆì–´?":"ëª¨ì§‘ì¤‘","ìžˆë‚˜ìš”":"ëª¨ì§‘ì¤‘","ìžˆë‚˜":"ëª¨ì§‘ì¤‘","ìžˆìŒ?":"ëª¨ì§‘ì¤‘",
    "ì—´ë ¸ì–´":"ëª¨ì§‘ì¤‘","ì—´ë ¸ëƒ":"ëª¨ì§‘ì¤‘","êµ¬í•¨":"ëª¨ì§‘ì¤‘",
    "ì¸ìŠ¤íƒ€":"ì¸ìŠ¤íƒ€ê·¸ëž¨","ìœ íˆ½":"ìœ íŠœë¸Œ","ì‡¼ì± ":"ì‡¼ì¸ ",
}
LIST_INTENT_WORDS = ("ì°¾ì•„","ë­ ìžˆì–´","ëª©ë¡","ì¶”ì²œ","ìžˆì–´","ìžˆë‚˜ìš”","ìžˆë‚˜","ë³´ì—¬ì¤˜","ê³¨ë¼ì¤˜","ê²€ìƒ‰","í• ë§Œí•œ","ê´œì°®ì€","ì–´ë–¤ ê²Œ","ê¶ê¸ˆ")
DETAIL_INTENT_WORDS = ("ê²½ìŸë¥ ","ë¦¬ë·°","ë§ˆê°","ì²´í—˜ ê¸°ê°„","ë°œí‘œ","ëª¨ì§‘ ì¸ì›","í˜œíƒ","í‚¤ì›Œë“œ","ë¯¸ì…˜")

def normalize_text(s: str) -> str:
    s2 = s
    for k, v in NORMALIZE_MAP.items():
        s2 = s2.replace(k, v)
    return s2

def fuzzy_pick(token: str, vocab: list[str], cutoff=0.8) -> Optional[str]:
    cand = get_close_matches(token, vocab, n=1, cutoff=cutoff)
    return cand[0] if cand else None

def detect_intent(text: str) -> str:
    s = (text or "").strip()
    if re.search(r"(ë°©ë²•|ì ˆì°¨|ì–´ë–»ê²Œ|ê°€ì´ë“œ|FAQ|ë¦¬ë·°\s*ì œì¶œ|í›„ê¸°\s*ì œì¶œ|ì—…ë¡œë“œ)", s):
        return "qa"
    if any(w in s for w in DETAIL_INTENT_WORDS):
        return "detail"
    if any(w in s for w in LIST_INTENT_WORDS) or re.search(r"(ìžˆì–´\??|ìžˆë‚˜ìš”|ì°¾ì•„ì¤˜|ë³´ì—¬ì¤˜|ì¶”ì²œí•´ì¤˜|ë­ê°€|ì–´ë–¤ê²Œ)", s):
        return "list"
    return "qa"

def parse_filters(text: str):
    raw = (text or "").strip()
    if not raw:
        return {"region": None, "prom": None, "channel": None, "status": None, "q": None}
    s = normalize_text(raw)

    # ì§€ì—­
    region = None
    for r in REGIONS:
        if re.search(rf"{r}(ì—|ì—ì„œ|ìª½|ê·¼ì²˜|ì§€ì—­|ìœ¼ë¡œ|ë¡œ)?", s):
            region = r; break
    if not region:
        for t in re.findall(r"[ê°€-íž£A-Za-z0-9]{2,}", s):
            pick = fuzzy_pick(t, REGIONS, cutoff=0.84)
            if pick: region = pick; break

    # ìƒíƒœ
    tl = s.lower()
    status = None
    if ("ëª¨ì§‘ì¤‘" in s) or ("open" in tl):
        status = "ëª¨ì§‘ì¤‘"
    elif ("ë§ˆê°" in s) or ("closed" in tl):
        status = "ë§ˆê°"
    elif re.search(r"(ìžˆì–´\??|ìžˆë‚˜ìš”|ìžˆë‚˜|ë°›ë‚˜ìš”|ë°›ì•„\??|ì—´ë ¸ì–´|ì—´ë ¸ëƒ|êµ¬í•¨)", s):
        status = "ëª¨ì§‘ì¤‘"

    # ìœ í˜•/ì±„ë„
    prom = next((p for p in PROM_MAP.keys() if p in s), None)
    if not prom:
        for t in re.findall(r"[ê°€-íž£A-Za-z0-9]{2,}", s):
            pick = fuzzy_pick(t, list(PROM_MAP.keys()), cutoff=0.84)
            if pick: prom = pick; break

    channel = next((c for c in CHANNEL_WORDS if c in s), None)
    if not channel:
        for t in re.findall(r"[ê°€-íž£A-Za-z0-9]{2,}", s):
            pick = fuzzy_pick(t, CHANNEL_WORDS, cutoff=0.8)
            if pick: channel = pick; break
    if not channel:
        low = s.lower()
        for name, aliases in CHANNEL_MAP.items():
            if name in s or any(a.lower() in low for a in aliases):
                channel = name
                break

    # í‚¤ì›Œë“œ
    exclude = {region, prom, channel, "ëª¨ì§‘ì¤‘", "ë§ˆê°", None}
    if region:
        for j in JOSA: exclude.add(region + j)
    REQUEST_SUFFIXES = ("í•´ì¤˜","í•´","í•´ì£¼ì„¸ìš”","í•´ì¤„ëž˜","ì£¼ì„¸ìš”","í•´ë³¼ê¹Œ","ì£¼ë¼","ì£¼ë¼ìš”","ì¢€")
    REQUEST_WORDS = {"ì¶”ì²œ","ì¶”ì²œí•´ì¤˜","ì•Œë ¤ì¤˜","ì°¾ì•„ì¤˜","ë³´ì—¬ì¤˜","ê³¨ë¼ì¤˜","ë§í•´ì¤˜","ê°€ë¥´ì³ì¤˜","ë¶€íƒ","ìš”ì²­"}

    kw = None
    for tok in re.findall(r"[ê°€-íž£A-Za-z0-9]{2,}", s):
        base = strip_josa(tok)
        if base in REQUEST_WORDS or base.endswith(REQUEST_SUFFIXES):
            continue
        if base in exclude: continue
        if base in REGIONS or base in PROM_MAP or base in CHANNEL_WORDS: continue
        if base in STOPWORDS: continue
        if "ìº íŽ˜ì¸" in base: continue
        if base.startswith(PREFIX_STOP) or (base.endswith("ì¸") and base[:-1] in PREFIX_STOP): continue
        if region and (base == region or region in base): continue
        kw = base; break

    return {"region": region, "prom": prom, "channel": channel, "status": status, "q": kw}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë§ˆí¬ë‹¤ìš´ ì¶œë ¥ í—¬í¼
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _mk_header_text(filt: dict) -> str:
    parts = []
    if filt.get("region"):  parts.append(f"ì§€ì—­={filt['region']}")
    if filt.get("prom"):    parts.append(f"ìœ í˜•={filt['prom']}")
    if filt.get("channel"): parts.append(f"ì±„ë„={filt['channel']}")
    if filt.get("status"):  parts.append(f"ìƒíƒœ={filt['status']}")
    if filt.get("q"):       parts.append(f"í‚¤ì›Œë“œ={filt['q']}")
    return ", ".join(parts) if parts else "ëª¨ë“  ìº íŽ˜ì¸"

def _rows_to_markdown_table(rows: list[dict]) -> str:
    """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë§ˆí¬ë‹¤ìš´ í‘œë¡œ ë³€í™˜ (í”„ë¡ íŠ¸ ReactMarkdown+GFMë¡œ ì˜ˆì˜ê²Œ ë Œë”ë¨)"""
    if not rows:
        return ""
    header = (
        "| # | ì œëª© | ì§€ì—­ | ìƒíƒœ | ì‹ ì²­ | ë‹¹ì²¨ | ë¦¬ë·° | ë¶ë§ˆí¬ | ëª¨ì§‘ê¸°ê°„ | ì²´í—˜ê¸°ê°„ |\n"
        "|---:|---|---|---|---:|---:|---:|---:|---|---|\n"
    )
    lines = []
    for i, r in enumerate(rows, 1):
        status = "ëª¨ì§‘ì¤‘" if r["RECRUIT_STATUS"] == "OPEN" else "ë§ˆê°"
        lines.append(
            f"| {i} | {r['TITLE']} | {r['region']} | {status}"
            f" | {r['total_app']} | {r['approved_cnt']} | {r['review_cnt']} | {r['bookmark_cnt']}"
            f" | {r['APPLY_START_DATE']}~{r['APPLY_END_DATE']}"
            f" | {r['EXP_START_DATE']}~{r['EXP_END_DATE']} |"
        )
    return header + "\n".join(lines)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# DB ê²€ìƒ‰ (ë¦¬ë·°ì–´ìš© ëª©ë¡/í†µê³„)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def db_search(params, limit=10):
    sql = """
      SELECT c.CAMPAIGN_IDX, c.TITLE,
             COALESCE(r.region,'ì˜¨ë¼ì¸/ì „êµ­') AS region,
             c.CAMPAIGN_TYPE, c.CAM_CATE_CODE, c.CHANNEL_CODE,
             c.RECRUIT_STATUS,
             DATE_FORMAT(c.APPLY_START_DATE,'%%Y-%%m-%%d') AS APPLY_START_DATE,
             DATE_FORMAT(c.APPLY_END_DATE,'%%Y-%%m-%%d')   AS APPLY_END_DATE,
             DATE_FORMAT(c.EXP_START_DATE,'%%Y-%%m-%%d')   AS EXP_START_DATE,
             DATE_FORMAT(c.EXP_END_DATE,'%%Y-%%m-%%d')     AS EXP_END_DATE,
             DATE_FORMAT(c.DEADLINE_DATE,'%%Y-%%m-%%d')    AS DEADLINE_DATE,
             COALESCE(s.total_app,0) AS total_app,
             COALESCE(s.approved_cnt,0) AS approved_cnt,
             COALESCE(rv.review_cnt,0) AS review_cnt,
             COALESCE(bm.bookmark_cnt,0) AS bookmark_cnt
      FROM tb_campaign c
      LEFT JOIN (
        SELECT CAMPAIGN_IDX,
          CASE
            WHEN ADDRESS LIKE '%%ì„œìš¸%%' THEN 'ì„œìš¸'
            WHEN ADDRESS LIKE '%%ê²½ê¸°%%' THEN 'ê²½ê¸°'
            WHEN ADDRESS LIKE '%%ì¸ì²œ%%' THEN 'ì¸ì²œ'
            WHEN ADDRESS LIKE '%%ë¶€ì‚°%%' THEN 'ë¶€ì‚°'
            WHEN ADDRESS LIKE '%%ëŒ€êµ¬%%' THEN 'ëŒ€êµ¬'
            WHEN ADDRESS LIKE '%%ê´‘ì£¼%%' THEN 'ê´‘ì£¼'
            WHEN ADDRESS LIKE '%%ëŒ€ì „%%' THEN 'ëŒ€ì „'
            WHEN ADDRESS LIKE '%%ìš¸ì‚°%%' THEN 'ìš¸ì‚°'
            WHEN ADDRESS LIKE '%%ì„¸ì¢…%%' THEN 'ì„¸ì¢…'
            WHEN ADDRESS LIKE '%%ê°•ì›%%' THEN 'ê°•ì›'
            WHEN ADDRESS LIKE '%%ì¶©ë¶%%' THEN 'ì¶©ë¶'
            WHEN ADDRESS LIKE '%%ì¶©ë‚¨%%' THEN 'ì¶©ë‚¨'
            WHEN ADDRESS LIKE '%%ì „ë¶%%' THEN 'ì „ë¶'
            WHEN ADDRESS LIKE '%%ì „ë‚¨%%' THEN 'ì „ë‚¨'
            WHEN ADDRESS LIKE '%%ê²½ë¶%%' THEN 'ê²½ë¶'
            WHEN ADDRESS LIKE '%%ê²½ë‚¨%%' THEN 'ê²½ë‚¨'
            WHEN ADDRESS LIKE '%%ì œì£¼%%' THEN 'ì œì£¼'
            ELSE 'ì˜¨ë¼ì¸/ì „êµ­'
          END AS region
        FROM tb_campaign_visit
        GROUP BY CAMPAIGN_IDX, region
      ) r ON r.CAMPAIGN_IDX=c.CAMPAIGN_IDX
      LEFT JOIN (
        SELECT
          CAMPAIGN_IDX,
          COUNT(*) AS total_app,
          SUM(CASE WHEN APPLY_STATUS_CODE='CAMAPP_APPROVED' THEN 1 ELSE 0 END) AS approved_cnt
        FROM tb_campaign_application
        WHERE IFNULL(DEL_YN,'N')='N'
        GROUP BY CAMPAIGN_IDX
      ) s ON s.CAMPAIGN_IDX=c.CAMPAIGN_IDX
      LEFT JOIN (
        SELECT ca.CAMPAIGN_IDX, COUNT(r.REVIEW_IDX) AS review_cnt
        FROM tb_review r
        JOIN tb_campaign_application ca ON ca.APPLICATION_IDX=r.APPLICATION_IDX
        GROUP BY ca.CAMPAIGN_IDX
      ) rv ON rv.CAMPAIGN_IDX=c.CAMPAIGN_IDX
      LEFT JOIN (
        SELECT CAMPAIGN_IDX, COUNT(*) AS bookmark_cnt
        FROM tb_bookmark
        GROUP BY CAMPAIGN_IDX
      ) bm ON bm.CAMPAIGN_IDX=c.CAMPAIGN_IDX
      WHERE IFNULL(c.DEL_YN,'N')='N'
    """
    args: list[Any] = []

    # ì§€ë‚œ ëª¨ì§‘ê¸°ê°„ ì œì™¸(ìƒì‹œ NULL í—ˆìš©)
    if params.get("status") == "ë§ˆê°":
        sql += " AND c.RECRUIT_STATUS='CLOSED'"
    else:
        sql += " AND (c.APPLY_END_DATE IS NULL OR DATE(c.APPLY_END_DATE) >= CURDATE())"

    # í‚¤ì›Œë“œ/ì§€ì—­/ìœ í˜•
    if params.get("q"):
        sql += " AND (c.TITLE LIKE %s OR c.MISSION LIKE %s OR c.KEYWORD_1 LIKE %s OR c.KEYWORD_2 LIKE %s OR c.KEYWORD_3 LIKE %s)"
        args += [f"%{params['q']}%"]*5
    if params.get("region"):
        sql += " AND COALESCE(r.region,'ì˜¨ë¼ì¸/ì „êµ­') = %s"
        args.append(params["region"])
    if params.get("prom"):
        code = PROM_MAP.get(params["prom"], params["prom"])
        sql += " AND c.CAMPAIGN_TYPE = %s"
        args.append(code)

    # ì±„ë„(ì•ˆì „ ì¡°ë¦½ + ë³„ì¹­ ì¤‘ë³µ ì œê±°)
    if params.get("channel"):
        ch_name = params["channel"]
        cand_codes = CHANNEL_CODES_BY_NAME.get(ch_name, [])
        aliases = CHANNEL_MAP.get(ch_name, [ch_name])

        uniq_aliases = []
        seen = set()
        for a in [ch_name] + aliases:
            low = a.lower()
            if low not in seen:
                uniq_aliases.append(a)
                seen.add(low)

        conds = []
        vals: list[Any] = []

        if cand_codes:
            placeholders = ",".join(["%s"] * len(cand_codes))
            conds.append(f"c.CHANNEL_CODE IN ({placeholders})")
            vals.extend(cand_codes)

        for alias in uniq_aliases:
            conds.append(
                "EXISTS (SELECT 1 FROM tb_common_code cc "
                "WHERE cc.code_id = c.CHANNEL_CODE "
                "AND cc.code_nm LIKE %s)"
            )
            vals.append(f"%{alias}%")

        for alias in uniq_aliases:
            conds.append("c.CHANNEL_CODE LIKE %s")
            vals.append(f"%{alias}%")

        sql += " AND (" + " OR ".join(conds) + ")"
        args += vals

    # ìƒíƒœ: ëª¨ì§‘ì¤‘
    if params.get("status") == "ëª¨ì§‘ì¤‘":
        sql += " AND c.RECRUIT_STATUS='OPEN'"

    # ì •ë ¬ + LIMIT
    sql += (
        " ORDER BY (c.RECRUIT_STATUS='OPEN') DESC, "
        "bm.bookmark_cnt DESC, s.total_app DESC, c.REG_DATE DESC LIMIT %s"
    )
    args.append(limit)

    with sql_conn() as conn, conn.cursor() as cur:
        cur.execute(sql, args)
        return cur.fetchall()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì†Œìƒê³µì¸(OWNER) / ë¦¬ë·°ì–´(REVIEWER)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def db_owner_stats(owner_id: int, limit=5):
    sql = """
      SELECT c.CAMPAIGN_IDX, c.TITLE,
             c.RECRUIT_STATUS,
             DATE_FORMAT(c.APPLY_START_DATE,'%%Y-%%m-%%d') AS APPLY_START_DATE,
             DATE_FORMAT(c.APPLY_END_DATE,'%%Y-%%m-%%d')   AS APPLY_END_DATE,
             DATE_FORMAT(c.ANNOUNCE_DATE,'%%Y-%%m-%%d')    AS ANNOUNCE_DATE,
             DATE_FORMAT(c.DEADLINE_DATE,'%%Y-%%m-%%d')    AS DEADLINE_DATE,
             COALESCE(s.total_app,0) AS total_app,
             COALESCE(s.approved_cnt,0) AS approved_cnt,
             COALESCE(rv.review_cnt,0) AS review_cnt,
             COALESCE(bm.bookmark_cnt,0) AS bookmark_cnt
      FROM tb_campaign c
      LEFT JOIN (
        SELECT
          CAMPAIGN_IDX,
          COUNT(*) AS total_app,
          SUM(CASE WHEN APPLY_STATUS_CODE='CAMAPP_APPROVED' THEN 1 ELSE 0 END) AS approved_cnt
        FROM tb_campaign_application
        WHERE IFNULL(DEL_YN,'N')='N'
        GROUP BY CAMPAIGN_IDX
      ) s ON s.CAMPAIGN_IDX=c.CAMPAIGN_IDX
      LEFT JOIN (
        SELECT ca.CAMPAIGN_IDX, COUNT(r.REVIEW_IDX) AS review_cnt
        FROM tb_review r
        JOIN tb_campaign_application ca ON ca.APPLICATION_IDX=r.APPLICATION_IDX
        GROUP BY ca.CAMPAIGN_IDX
      ) rv ON rv.CAMPAIGN_IDX=c.CAMPAIGN_IDX
      LEFT JOIN (
        SELECT CAMPAIGN_IDX, COUNT(*) AS bookmark_cnt
        FROM tb_bookmark
        GROUP BY CAMPAIGN_IDX
      ) bm ON bm.CAMPAIGN_IDX=c.CAMPAIGN_IDX
      WHERE IFNULL(c.DEL_YN,'N')='N'
        AND c.OWNER_ID = %s
      ORDER BY c.REG_DATE DESC
      LIMIT %s
    """
    with sql_conn() as conn, conn.cursor() as cur:
        cur.execute(sql, (owner_id, limit))
        return cur.fetchall()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ê²½ìŸë¥  ê³„ì‚° (ì œëª© í‚¤ì›Œë“œ ê¸°ë°˜)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def db_campaign_competition(title_kw: str, region: Optional[str] = None):
    sql = """
      SELECT
        c.CAMPAIGN_IDX,
        c.TITLE,
        COALESCE(rm.region,'ì˜¨ë¼ì¸/ì „êµ­') AS region,
        c.RECRUIT_STATUS,
        c.RECRUIT_COUNT AS recruit_slots,
        COALESCE(a.total_app,0)   AS total_app,
        COALESCE(a.approved_cnt,0) AS approved_cnt,
        DATE_FORMAT(c.APPLY_START_DATE,'%%Y-%%m-%%d') AS APPLY_START_DATE,
        DATE_FORMAT(c.APPLY_END_DATE,'%%Y-%%m-%%d')   AS APPLY_END_DATE
      FROM tb_campaign c
      LEFT JOIN (
        SELECT CAMPAIGN_IDX,
               COUNT(*) AS total_app,
               SUM(CASE WHEN APPLY_STATUS_CODE='CAMAPP_APPROVED' THEN 1 ELSE 0 END) AS approved_cnt
        FROM tb_campaign_application
        WHERE IFNULL(DEL_YN,'N')='N'
        GROUP BY CAMPAIGN_IDX
      ) a ON a.CAMPAIGN_IDX = c.CAMPAIGN_IDX
      LEFT JOIN (
        SELECT CAMPAIGN_IDX,
          CASE
            WHEN ADDRESS LIKE '%%ì„œìš¸%%' THEN 'ì„œìš¸'
            WHEN ADDRESS LIKE '%%ê²½ê¸°%%' THEN 'ê²½ê¸°'
            WHEN ADDRESS LIKE '%%ì¸ì²œ%%' THEN 'ì¸ì²œ'
            WHEN ADDRESS LIKE '%%ë¶€ì‚°%%' THEN 'ë¶€ì‚°'
            WHEN ADDRESS LIKE '%%ëŒ€êµ¬%%' THEN 'ëŒ€êµ¬'
            WHEN ADDRESS LIKE '%%ê´‘ì£¼%%' THEN 'ê´‘ì£¼'
            WHEN ADDRESS LIKE '%%ëŒ€ì „%%' THEN 'ëŒ€ì „'
            WHEN ADDRESS LIKE '%%ìš¸ì‚°%%' THEN 'ìš¸ì‚°'
            WHEN ADDRESS LIKE '%%ì„¸ì¢…%%' THEN 'ì„¸ì¢…'
            WHEN ADDRESS LIKE '%%ê°•ì›%%' THEN 'ê°•ì›'
            WHEN ADDRESS LIKE '%%ì¶©ë¶%%' THEN 'ì¶©ë¶'
            WHEN ADDRESS LIKE '%%ì¶©ë‚¨%%' THEN 'ì¶©ë‚¨'
            WHEN ADDRESS LIKE '%%ì „ë¶%%' THEN 'ì „ë¶'
            WHEN ADDRESS LIKE '%%ì „ë‚¨%%' THEN 'ì „ë‚¨'
            WHEN ADDRESS LIKE '%%ê²½ë¶%%' THEN 'ê²½ë¶'
            WHEN ADDRESS LIKE '%%ê²½ë‚¨%%' THEN 'ê²½ë‚¨'
            WHEN ADDRESS LIKE '%%ì œì£¼%%' THEN 'ì œì£¼'
            ELSE 'ì˜¨ë¼ì¸/ì „êµ­'
          END AS region
        FROM tb_campaign_visit
        GROUP BY CAMPAIGN_IDX, region
      ) rm ON rm.CAMPAIGN_IDX = c.CAMPAIGN_IDX
      WHERE IFNULL(c.DEL_YN,'N')='N'
        AND c.TITLE LIKE %s
      {region_filter}
      ORDER BY c.REG_DATE DESC
      LIMIT 1
    """.format(region_filter=" AND COALESCE(rm.region,'ì˜¨ë¼ì¸/ì „êµ­')=%s" if region else "")
    args = [f"%{title_kw}%"] + ([region] if region else [])

    with sql_conn() as conn, conn.cursor() as cur:
        cur.execute(sql, args)
        row = cur.fetchone()

    if not row:
        return None

    slots = int(row["recruit_slots"] or 0)
    apps  = int(row["total_app"] or 0)
    comp_ratio = round(apps / slots, 2) if slots > 0 else None
    comp_pct   = round(apps / slots * 100, 1) if slots > 0 else None

    row["competition_ratio"] = comp_ratio
    row["competition_pct"]   = comp_pct
    return row

def extract_title_keyword_for_detail(msg: str) -> Optional[str]:
    s = (msg or "").strip()
    # ë”°ì˜´í‘œ ì•ˆ í…ìŠ¤íŠ¸ ìš°ì„ 
    m = re.search(r"[\"'â€œâ€â€˜â€™](.+?)[\"'â€œâ€â€˜â€™]", s)
    if m:
        kw = m.group(1).strip()
        return kw if kw else None
    # ìž¡ë‹¨ì–´ ì œê±° í›„ ì²« ìœ íš¨ í† í°
    s = s.replace("ìº íŽ˜ì¸", " ").replace("ê²½ìŸë¥ ", " ")
    toks = [t for t in re.findall(r"[ê°€-íž£A-Za-z0-9]+", s) if len(t) >= 2]
    bad = {
        "ìº íŽ˜ì¸","ê²½ìŸë¥ ","ë¦¬ë·°","ëª¨ì§‘","ëª¨ì§‘ì¤‘","ë§ˆê°","ì•Œë ¤ì¤˜","ì¢€",
        "ì œëª©","í‚¤ì›Œë“œ","ë°©ë²•","ì œì¶œ","ì—…ë¡œë“œ","ì ˆì°¨","ì¶”ì²œ","ì°¾ì•„ì¤˜",
        "ë³´ì—¬ì¤˜","ê³¨ë¼ì¤˜","í•´ì£¼ì„¸ìš”","í•´ì¤˜","í•´", "ì–¸ì œ","ì–´ë””","ê¸°ê°„"
    }
    toks = [t for t in toks if t not in bad]
    return toks[0] if toks else None

REVIEWER_TRIGGERS = {
    "apps": ("ë‚´ ì‹ ì²­", "ë‚´ê°€ ì‹ ì²­", "ì‹ ì²­ í˜„í™©", "ì§€ì› í˜„í™©"),
    "bookmarks": ("ë‚´ ë¶ë§ˆí¬", "ì €ìž¥í•œ ìº íŽ˜ì¸", "ì°œí•œ ìº íŽ˜ì¸"),
    "reviews": ("ë‚´ ë¦¬ë·°", "ìž‘ì„±í•œ ë¦¬ë·°", "ë¦¬ë·° ì œì¶œ í˜„í™©"),
    "deadlines": ("ë¦¬ë·° ë§ˆê°", "ë§ˆê°ì¼", "ë¦¬ë·° ì œì¶œ ê¸°í•œ"),
}
def detect_reviewer_intent(text: str) -> Optional[str]:
    s = (text or "").strip()
    for intent, kws in REVIEWER_TRIGGERS.items():
        if any(k in s for k in kws):
            return intent
    return None

def db_my_applications(user_id: int):
    sql = """
      SELECT c.TITLE, c.RECRUIT_STATUS,
             DATE_FORMAT(c.APPLY_START_DATE,'%%Y-%%m-%%d') AS APPLY_START_DATE,
             DATE_FORMAT(c.APPLY_END_DATE,'%%Y-%%m-%%d')   AS APPLY_END_DATE,
             DATE_FORMAT(c.DEADLINE_DATE,'%%Y-%%m-%%d')    AS DEADLINE_DATE,
             a.APPLY_STATUS_CODE
      FROM tb_campaign_application a
      JOIN tb_campaign c ON c.CAMPAIGN_IDX=a.CAMPAIGN_IDX
      WHERE a.USER_ID=%s AND IFNULL(a.DEL_YN,'N')='N'
      ORDER BY a.APPLY_DATE DESC LIMIT 5
    """
    with sql_conn() as conn, conn.cursor() as cur:
        cur.execute(sql, (user_id,))
        return cur.fetchall()

def db_my_bookmarks(user_id: int):
    sql = """
      SELECT c.TITLE, c.RECRUIT_STATUS,
             DATE_FORMAT(c.APPLY_END_DATE,'%%Y-%%m-%%d') AS APPLY_END_DATE
      FROM tb_bookmark b
      JOIN tb_campaign c ON c.CAMPAIGN_IDX=b.CAMPAIGN_IDX
      WHERE b.USER_ID=%s
      ORDER BY b.REG_DATE DESC LIMIT 5
    """
    with sql_conn() as conn, conn.cursor() as cur:
        cur.execute(sql, (user_id,))
        return cur.fetchall()

def db_my_reviews(user_id: int):
    sql = """
      SELECT c.TITLE,
             DATE_FORMAT(c.DEADLINE_DATE,'%%Y-%%m-%%d') AS DEADLINE_DATE,
             r.REVIEW_IDX
      FROM tb_review r
      JOIN tb_campaign_application a ON a.APPLICATION_IDX=r.APPLICATION_IDX
      JOIN tb_campaign c ON c.CAMPAIGN_IDX=a.CAMPAIGN_IDX
      WHERE a.USER_ID=%s
      ORDER BY r.REG_DATE DESC LIMIT 5
    """
    with sql_conn() as conn, conn.cursor() as cur:
        cur.execute(sql, (user_id,))
        return cur.fetchall()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# RAG
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _respond_rag(req: ChatReq):
    ctx_obj = retrieve_context(req.message, req.top_k)
    ctx_plain = (ctx_obj.get("plain") or "").strip()
    if not ctx_plain:
        retry_msg = f"{req.message} ê°€ì´ë“œ FAQ ì •ì±… ë„ì›€ë§ ëª¨ì§‘ì¤‘ ì§€ì—­ ì±„ë„ ìœ í˜• ê²½ìŸë¥  ì‹ ì²­ìž ë¦¬ë·° ì œì¶œ ë¶ë§ˆí¬"
        ctx_obj = retrieve_context(retry_msg, max(req.top_k, 10))
        ctx_plain = (ctx_obj.get("plain") or "").strip()
    if not ctx_plain:
        def noctx_gen():
            yield "data: ì•„ì§ ë‚´ë¶€ ë¬¸ì„œì—ì„œ ë‹µì„ ëª» ì°¾ì•˜ì–´ìš”. ì˜ˆ) 'ì„œìš¸ì— ë¸”ë¡œê·¸ ê°€ëŠ¥í•œ ê±° ìžˆì–´?' ì²˜ëŸ¼ ìžì—°ì–´ë¡œ íŽ¸í•˜ê²Œ ë¬¼ì–´ë³´ì…”ë„ ë¼ìš”.\n\n"
            yield "data: [DONE]\n\n"
        return StreamingResponse(noctx_gen(), media_type="text/event-stream",
                                 headers={"Cache-Control":"no-cache","X-Accel-Buffering":"no"})
    messages = [
        {"role": "system", "content": SYSTEM},
        {"role": "system", "content": f"ì»¨í…ìŠ¤íŠ¸(ë²ˆí˜¸ì™€ ì¶œì²˜ í¬í•¨):\n{ctx_plain}"},
        {"role": "user", "content": req.message},
    ]
    def gen_rag():
        try:
            stream = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=messages,
                temperature=0.2,
                stream=True,
            )
            for chunk in stream:
                delta = chunk.choices[0].delta.content or ""
                if delta:
                    delta = clean_response_piece(delta)
                    if delta:
                        yield f"data: {delta}\n\n"
        except Exception as e:
            yield f"data: [ERROR] {str(e)}\n\n"
        yield "data: [DONE]\n\n"
    return StreamingResponse(gen_rag(), media_type="text/event-stream",
                             headers={"Cache-Control":"no-cache","X-Accel-Buffering":"no"})

def _should_list(msg: str, filt: dict, intent: str) -> bool:
    if re.search(r"(ë°©ë²•|ì ˆì°¨|ì–´ë–»ê²Œ|ê°€ì´ë“œ|FAQ|ë¦¬ë·°\s*ì œì¶œ|í›„ê¸°\s*ì œì¶œ|ì—…ë¡œë“œ)", msg):
        return False
    has_strict_filter = any([filt.get("region"), filt.get("prom"), filt.get("channel"), filt.get("status")])
    return has_strict_filter or intent == "list"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìŠ¤íŠ¸ë¦¬ë° ì±—
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
OWNER_TRIGGERS = ("ë‚´ ìº íŽ˜ì¸", "ë‚´ê°€ ì˜¬ë¦°", "ìš°ë¦¬ ê°€ê²Œ", "ë‚´ê°€ ë“±ë¡", "ë‚´ ìº íŽ˜ì¸ë“¤")
def is_owner_query(text: str) -> bool:
    s = (text or "").strip()
    return any(t in s for t in OWNER_TRIGGERS)

@app.post("/chat/stream")
def chat_stream(req: ChatReq, request: Request):
    intent = detect_intent(req.message)
    filt = parse_filters(req.message)

    # ë¦¬ë·°ì–´
    rev_intent = detect_reviewer_intent(req.message)
    if rev_intent:
        user_id = req.user_id
        def gen_reviewer():
            if not user_id:
                yield "data: âš ï¸ ë¡œê·¸ì¸ í›„ ì´ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤. (user_id í•„ìš”)\n\n"
                yield "data: [DONE]\n\n"; return
            if rev_intent == "apps":
                rows = db_my_applications(user_id)
                if not rows: yield "data: ðŸ“Œ ì‹ ì²­í•œ ìº íŽ˜ì¸ì´ ì—†ìŠµë‹ˆë‹¤.\n\n"
                else:
                    yield "data: ðŸ“Œ ìµœê·¼ ì‹ ì²­ í˜„í™©:\n\n"
                    for r in rows:
                        yield f"data: - {r['TITLE']} Â· ìƒíƒœ:{'ëª¨ì§‘ì¤‘' if r['RECRUIT_STATUS']=='OPEN' else 'ë§ˆê°'} (ì‹ ì²­:{r['APPLY_START_DATE']}~{r['APPLY_END_DATE']}) Â· ë¦¬ë·°ë§ˆê°:{r['DEADLINE_DATE']}\n\n"
            elif rev_intent == "bookmarks":
                rows = db_my_bookmarks(user_id)
                if not rows: yield "data: ðŸ“Œ ì €ìž¥í•œ ìº íŽ˜ì¸ì´ ì—†ìŠµë‹ˆë‹¤.\n\n"
                else:
                    yield "data: ðŸ“Œ ë‚´ ë¶ë§ˆí¬ ëª©ë¡:\n\n"
                    for r in rows:
                        yield f"data: - {r['TITLE']} Â· ìƒíƒœ:{'ëª¨ì§‘ì¤‘' if r['RECRUIT_STATUS']=='OPEN' else 'ë§ˆê°'} (ë§ˆê°:{r['APPLY_END_DATE']})\n\n"
            elif rev_intent == "reviews":
                rows = db_my_reviews(user_id)
                if not rows: yield "data: ðŸ“Œ ì œì¶œí•œ ë¦¬ë·°ê°€ ì—†ìŠµë‹ˆë‹¤.\n\n"
                else:
                    yield "data: ðŸ“Œ ë‚´ ë¦¬ë·° ì œì¶œ í˜„í™©:\n\n"
                    for r in rows:
                        yield f"data: - {r['TITLE']} Â· ë¦¬ë·°ID:{r['REVIEW_IDX']} (ë¦¬ë·°ë§ˆê°:{r['DEADLINE_DATE']})\n\n"
            elif rev_intent == "deadlines":
                rows = db_my_applications(user_id)
                if not rows: yield "data: ðŸ“Œ ë¦¬ë·° ë§ˆê°ì¼ ê´€ë ¨ ìº íŽ˜ì¸ì´ ì—†ìŠµë‹ˆë‹¤.\n\n"
                else:
                    yield "data: ðŸ“Œ ë‚´ê°€ ì°¸ì—¬í•œ ìº íŽ˜ì¸ ë¦¬ë·° ë§ˆê°ì¼:\n\n"
                    for r in rows:
                        yield f"data: - {r['TITLE']} Â· ë¦¬ë·°ë§ˆê°:{r['DEADLINE_DATE']}\n\n"
            yield "data: [DONE]\n\n"
        return StreamingResponse(gen_reviewer(), media_type="text/event-stream",
                                 headers={"Cache-Control":"no-cache","X-Accel-Buffering":"no"})

    # ì˜¤ë„ˆ
    if is_owner_query(req.message):
        owner_id = req.user_id
        def gen_owner():
            if not owner_id:
                yield "data: âš ï¸ ë¡œê·¸ì¸ í›„ ì´ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤. (user_id í•„ìš”)\n\n"
                yield "data: [DONE]\n\n"; return
            rows = db_owner_stats(owner_id, limit=5)
            if not rows:
                yield "data: ðŸ“Š í˜„ìž¬ ë“±ë¡í•œ ìº íŽ˜ì¸ì´ ì—†ìŠµë‹ˆë‹¤.\n\n"
                yield "data: [DONE]\n\n"; return
            yield f"data: ðŸ“Š ë‚´ ìº íŽ˜ì¸ í˜„í™© (ìµœê·¼ {len(rows)}ê±´)\n\n"
            for i, r in enumerate(rows, 1):
                line = (
                    f"{i}. {r['TITLE']} Â· ìƒíƒœ:{'ëª¨ì§‘ì¤‘' if r['RECRUIT_STATUS']=='OPEN' else 'ë§ˆê°'} "
                    f"(ì‹ ì²­:{r['total_app']}, ë‹¹ì²¨:{r['approved_cnt']}, ë¦¬ë·°:{r['review_cnt']}, ë¶ë§ˆí¬:{r['bookmark_cnt']}) "
                    f"ëª¨ì§‘:{r['APPLY_START_DATE']}~{r['APPLY_END_DATE']} | ë°œí‘œ:{r['ANNOUNCE_DATE']} | ë¦¬ë·°ë§ˆê°:{r['DEADLINE_DATE']}"
                )
                yield f"data: {line}\n\n"
            yield "data: [DONE]\n\n"
        return StreamingResponse(gen_owner(), media_type="text/event-stream",
                                 headers={"Cache-Control":"no-cache","X-Accel-Buffering":"no"})

    # ê²½ìŸë¥ 
    if "ê²½ìŸë¥ " in req.message:
        title_kw = filt.get("q") or extract_title_keyword_for_detail(req.message)
        def gen_comp():
            if not title_kw:
                yield "data: ê²½ìŸë¥ ì„ ì•Œë ¤ë©´ ìº íŽ˜ì¸ ì œëª©ì˜ í•µì‹¬ ë‹¨ì–´ê°€ í•„ìš”í•´ìš”. ì˜ˆ: \"ì¸ìƒë§¥ì£¼ ê²½ìŸë¥ \"\n\n"
                yield "data: [DONE]\n\n"; return
            row = db_campaign_competition(title_kw, region=filt.get("region"))
            if not row:
                yield f"data: '{title_kw}'ë¡œ ì°¾ì€ ìº íŽ˜ì¸ì´ ì—†ì–´ìš”. ì œëª©ì˜ ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ë‹¤ì‹œ ì‹œë„í•´ ë³´ì„¸ìš”.\n\n"
                yield "data: [DONE]\n\n"; return

            status = "ëª¨ì§‘ì¤‘" if row["RECRUIT_STATUS"] == "OPEN" else "ë§ˆê°"
            slots  = int(row["recruit_slots"] or 0)
            apps   = int(row["total_app"] or 0)
            ratio  = row["competition_ratio"]; pct = row["competition_pct"]

            yield f"data: ### ðŸ”Ž {row['TITLE']} Â· {row['region']} Â· ìƒíƒœ:{status}\n\n"
            yield f"data: - ëª¨ì§‘ê¸°ê°„: **{row['APPLY_START_DATE']} ~ {row['APPLY_END_DATE']}**\n\n"
            yield f"data: - ì‹ ì²­ **{apps}ëª…** / ëª¨ì§‘ **{slots}ëª…**\n\n"
            if ratio is not None:
                yield f"data: - ê²½ìŸë¥ : **ì•½ {ratio}ë°° (â‰ˆ {pct}%)**\n\n"
            else:
                yield "data: - ê²½ìŸë¥ : ëª¨ì§‘ì •ì› ì •ë³´ë¥¼ ì°¾ì§€ ëª»í•´ ë°°ìˆ˜ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ì–´ìš”.\n\n"
            if row.get("approved_cnt") is not None:
                yield f"data: - ë‹¹ì²¨(ì„ ì •) ìˆ˜: **{row['approved_cnt']}ëª…**\n\n"
            yield "data: [DONE]\n\n"
        return StreamingResponse(gen_comp(), media_type="text/event-stream",
                                 headers={"Cache-Control":"no-cache","X-Accel-Buffering":"no"})

    # ì¹´ìš´íŠ¸
    if re.search(r"(ëª‡\s*ê°œ|ëª‡\s*ê±´|ëª‡\s*ëª…|ì´\s*ëª‡)", req.message):
        filt_for_count = {**filt, "q": None}
        rows = db_search(filt_for_count, limit=9999)
        def gen_count():
            cnt = len(rows)
            hdr_text = _mk_header_text(filt_for_count)
            yield f"data: ### ðŸ“Š í˜„ìž¬ (**{hdr_text}**) ì¡°ê±´ì˜ ìº íŽ˜ì¸ ìˆ˜\n\n"
            yield f"data: - **ì´ {cnt}ê±´**\n\n"
            if cnt > 0:
                yield "data: - ìƒìœ„ ëª‡ ê°œë¥¼ í‘œë¡œ ë³´ê³  ì‹¶ìœ¼ë©´ **â€œìƒìœ„ 5ê°œ ë³´ì—¬ì¤˜â€** ì²˜ëŸ¼ ë§í•´ ë³´ì„¸ìš”.\n\n"
            yield "data: [DONE]\n\n"
        return StreamingResponse(gen_count(), media_type="text/event-stream",
                                 headers={"Cache-Control": "no-cache","X-Accel-Buffering":"no"})

    # QA
    if intent == "qa":
        return _respond_rag(req)

    # ëª©ë¡/íƒìƒ‰ (0ê±´ì´ë©´ 0ê±´ ê³ ì§€, ì±„ë„ ì™„í™” í´ë°± ì—†ìŒ)
    if _should_list(req.message, filt, intent):
        rows = db_search(filt, limit=10)
        def gen_list():
            hdr_text = _mk_header_text(filt)
            if not rows:
                yield f"data: ### ðŸ”Ž ê²€ìƒ‰ê²°ê³¼ (**{hdr_text}**)\n\n"
                yield f"data: - **ì´ 0ê±´**ìž…ë‹ˆë‹¤.\n\n"
                yield "data: - ì¡°ê±´ì„ ì¡°ê¸ˆ ë„“í˜€ ë³´ì‹œê² ì–´ìš”? (ì˜ˆ: ì±„ë„/í‚¤ì›Œë“œ ì œê±°)\n\n"
                yield "data: [DONE]\n\n"
                return
            yield f"data: ### ðŸ”Ž ê²€ìƒ‰ê²°ê³¼ (**{hdr_text}**) ìƒìœ„ {len(rows)}ê±´\n\n"
            table_md = _rows_to_markdown_table(rows)
            for chunk in table_md.splitlines(True):
                yield f"data: {chunk}"
            yield "data: \n\n"
            yield "data: - íŠ¹ì • ìº íŽ˜ì¸ ìƒì„¸ê°€ ê¶ê¸ˆí•˜ë©´ **ì œëª© í•µì‹¬ ë‹¨ì–´**ë¡œ ë¬¼ì–´ë³´ì„¸ìš”. (ì˜ˆ: `OOO ê²½ìŸë¥ /ë¦¬ë·° ë§ˆê°?`)\n\n"
            yield "data: [DONE]\n\n"
        return StreamingResponse(gen_list(), media_type="text/event-stream",
                                 headers={"Cache-Control":"no-cache","X-Accel-Buffering":"no"})

    # ë‚˜ë¨¸ì§€: RAG
    return _respond_rag(req)

def await_disconnected(request: Request) -> bool:
    return False
